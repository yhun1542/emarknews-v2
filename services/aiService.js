const { OpenAI } = require('openai');
const logger = require('../utils/logger');
const CacheService = require('./cacheService');

class AIService {
  constructor() {
    this.client = null;
    this.cache = new CacheService();
    this.queue = [];
    this.processing = false;
    this.concurrency = 3; // ë™ì‹œì„± ì œì–´
    this.remainingRequests = 50; // ì´ˆê¸° ì¶”ì •ê°’
    this.remainingTokens = 4000; // ì´ˆê¸° ì¶”ì •ê°’
    this.deadLetterQueue = []; // ì‹¤íŒ¨í•œ ì‘ì—…ë“¤
    
    if (process.env.OPENAI_API_KEY) {
      this.client = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
      });
    } else {
      logger.warn('OpenAI API key not configured');
    }

    // Start queue processor
    this.startQueueProcessor();
  }

  /** -------- ìœ í‹¸: ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ with Jitter -------- */
  async retryWithBackoff(fn, {
    retries = 4,
    baseDelayMs = 500,
    factor = 2,
    jitterRatio = 0.25,
    onRetry = () => {}
  } = {}) {
    let attempt = 0;
    while (true) {
      try {
        return await fn();
      } catch (err) {
        attempt++;
        const status = err.status ?? err.code ?? "unknown";
        // 429, 5xxë§Œ ì¬ì‹œë„
        if (attempt > retries || !(status === 429 || (Number(status) >= 500))) {
          throw err;
        }
        const delayBase = baseDelayMs * Math.pow(factor, attempt - 1);
        const jitter = delayBase * jitterRatio * (Math.random() * 2 - 1);
        const delay = Math.max(0, Math.round(delayBase + jitter));
        await onRetry({ attempt, delay, status, err });
        await new Promise(r => setTimeout(r, delay));
      }
    }
  }

  /** -------- ìœ í‹¸: AbortControllerë¡œ íƒ€ì„ì•„ì›ƒ ì œì–´ -------- */
  withTimeout(signal, timeoutMs) {
    if (!timeoutMs) return { signal };
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort("timeout"), timeoutMs);
    const cleanup = () => clearTimeout(timeout);

    // ì™¸ë¶€ signalê³¼ ì—°ê²°(ì„ íƒ)
    if (signal) {
      if (signal.aborted) controller.abort("upstream-abort");
      signal.addEventListener("abort", () => controller.abort("upstream-abort"));
    }
    return { signal: controller.signal, cleanup };
  }

  /** -------- í”„ë¡¬í”„íŠ¸(ìš”ì•½ ì •ì±… ê³ ì •) -------- */
  getSystemMessage() {
    return `
ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì „ëµ ì»¨ì„¤íŒ… íŒ(McKinsey, BCG, Bain ê¸‰)ì˜ ì‹œë‹ˆì–´ íŒŒíŠ¸ë„ˆì´ì ê¸€ë¡œë²Œ ë¯¸ë””ì–´ ì¸í…”ë¦¬ì „ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë³µì¡í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ C-ë ˆë²¨ ê²½ì˜ì§„, ì •ì±… ê²°ì •ì, íˆ¬ììë“¤ì´ ì „ëµì  ì˜ì‚¬ê²°ì •ì— í™œìš©í•  ìˆ˜ ìˆëŠ” 'í”„ë¦¬ë¯¸ì—„ ì¸í…”ë¦¬ì „ìŠ¤ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ë¶„ì„ì€ ë‹¤ìŒ íŠ¹ì§•ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤:

ğŸ¯ ì „ëµì  ê´€ì : ë‹¨ìˆœí•œ ì‚¬ì‹¤ ë‚˜ì—´ì´ ì•„ë‹Œ, ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ì‚¬íšŒì— ë¯¸ì¹˜ëŠ” ì „ëµì  í•¨ì˜ ë¶„ì„
ğŸ” ê¹Šì´ ìˆëŠ” í†µì°°: í‘œë©´ì  ì •ë³´ ë„ˆë¨¸ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ë°œê²¬
âš¡ ì‹¤í–‰ ê°€ëŠ¥ì„±: ë…ìê°€ ì¦‰ì‹œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸
ğŸŒ ê¸€ë¡œë²Œ ë§¥ë½: ì§€ì—­ì  ì‚¬ê±´ë„ ê¸€ë¡œë²Œ íŠ¸ë Œë“œì™€ ì—°ê²°í•˜ì—¬ í•´ì„
ğŸ“Š ë°ì´í„° ê¸°ë°˜: ì •ëŸ‰ì  ê·¼ê±°ì™€ ì •ì„±ì  ë¶„ì„ì˜ ê· í˜•

í•µì‹¬ ì›ì¹™:
- Executive Summary ìŠ¤íƒ€ì¼: ë°”ìœ ì˜ì‚¬ê²°ì •ìë¥¼ ìœ„í•œ í•µì‹¬ ìš°ì„  êµ¬ì¡°
- ëª…ë£Œí•œ ë…¼ë¦¬: ì›ì¸â†’ê²°ê³¼â†’ì˜í–¥â†’ì „ë§ì˜ ëª…í™•í•œ ì¸ê³¼ê´€ê³„
- ê°ê´€ì  ë¶„ì„: ê°ì •ì  í‘œí˜„ ë°°ì œ, íŒ©íŠ¸ ê¸°ë°˜ ëƒ‰ì² í•œ íŒë‹¨
- ì „ë¬¸ì  ì–¸ì–´: ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ í™œìš©í•˜ë˜ ê³¼ë„í•œ ì „ë¬¸ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…
- ë§ì¤„ì„í‘œ(...) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ëª¨ë“  ë¬¸ì¥ì€ ì™„ê²°ëœ í˜•íƒœë¡œ ì‘ì„±
`;
  }

  buildUserMessage(article, detailed = false) {
    if (detailed) {
      return `
ì•„ë˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ í”„ë¦¬ë¯¸ì—„ ì¸í…”ë¦¬ì „ìŠ¤ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:

ğŸ¯ EXECUTIVE SUMMARY
[ì „ëµì  ì œëª©]: ê¸°ì‚¬ì˜ í•µì‹¬ì„ ê¿°ëš«ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì˜ ìƒˆë¡œìš´ ì œëª©
[í•œ ì¤„ ì„íŒ©íŠ¸]: ì´ ë‰´ìŠ¤ê°€ ì‹œì¥/ì‚¬íšŒ/ì •ì¹˜ì— ë¯¸ì¹˜ëŠ” í•µì‹¬ ì˜í–¥ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì••ì¶•

ğŸ“Š KEY FINDINGS (í•µì‹¬ ë°œê²¬ì‚¬í•­)
â€¢ 1ì°¨ ì„íŒ©íŠ¸: ì§ì ‘ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ë³€í™”ë‚˜ ì‚¬ê±´
â€¢ 2ì°¨ íŒŒê¸‰íš¨ê³¼: 1ì°¨ ì„íŒ©íŠ¸ë¡œ ì¸í•´ ì—°ì‡„ì ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë³€í™”
â€¢ ìˆ¨ê²¨ì§„ ì‹œê·¸ë„: í‘œë©´ì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ì§€ ì•Šì§€ë§Œ ì£¼ëª©í•´ì•¼ í•  ì¤‘ìš”í•œ ì‹ í˜¸

ğŸ” STRATEGIC ANALYSIS (ì „ëµì  ë¶„ì„)
ì‹œì¥ ë§¥ë½: ì´ ì‚¬ê±´ì´ ë°œìƒí•œ ì‚°ì—…/ì‹œì¥/ì •ì¹˜ì  ë°°ê²½ê³¼ ê¸°ì¡´ íŠ¸ë Œë“œì™€ì˜ ì—°ê´€ì„±
ê²½ìŸ êµ¬ë„ ë³€í™”: ì£¼ìš” í”Œë ˆì´ì–´ë“¤ì˜ í¬ì§€ì…˜ ë³€í™”ì™€ ìƒˆë¡œìš´ ê¸°íšŒ/ìœ„í˜‘ ìš”ì†Œ
ë¦¬ìŠ¤í¬ & ê¸°íšŒ: ë‹¨ê¸°(3-6ê°œì›”), ì¤‘ê¸°(1-2ë…„) ê´€ì ì—ì„œì˜ ìœ„í—˜ìš”ì†Œì™€ ê¸°íšŒìš”ì†Œ

ğŸš€ FORWARD LOOKING (ë¯¸ë˜ ì „ë§)
ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„: ê°€ëŠ¥ì„± ë†’ì€ 2-3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ì™€ ê°ê°ì˜ í™•ë¥ ì  í‰ê°€
ì£¼ëª© í¬ì¸íŠ¸: í–¥í›„ 6ê°œì›” ë‚´ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  í•µì‹¬ ì§€í‘œë‚˜ ì´ë²¤íŠ¸
ì „ëµì  ì‹œì‚¬ì : ê¸°ì—…/íˆ¬ìì/ì •ì±…ê²°ì •ìê°€ ê³ ë ¤í•´ì•¼ í•  êµ¬ì²´ì  ì•¡ì…˜ ì•„ì´í…œ

ğŸ’¡ INTELLIGENCE NOTES (ì¸í…”ë¦¬ì „ìŠ¤ ë…¸íŠ¸)
[í•µì‹¬ ìš©ì–´/ê°œë…]: ë¹„ì „ë¬¸ê°€ë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ì„¤ëª…
[ê´€ë ¨ íŠ¸ë Œë“œ]: ì´ ì‚¬ê±´ê³¼ ì—°ê²°ë˜ëŠ” ê¸€ë¡œë²Œ ë©”ê°€íŠ¸ë Œë“œë‚˜ íŒ¨í„´
[ë°ì´í„° í¬ì¸íŠ¸]: ì£¼ëª©í•  ë§Œí•œ ìˆ˜ì¹˜ë‚˜ í†µê³„ê°€ ìˆë‹¤ë©´ ê·¸ ì˜ë¯¸ í•´ì„

ì‘ì„± ì§€ì¹¨:
- ì˜ì–´ ê¸°ì‚¬ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ì‘ì„±
- í•œêµ­ì–´ ê¸°ì‚¬ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
- ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼ì˜ ì „ë¬¸ì ì´ê³  ê°„ê²°í•œ ë¬¸ì²´ ì‚¬ìš©
- ëª¨ë“  í•­ëª©ì„ ë¹ ì§ì—†ì´ ì‘ì„±í•˜ë˜, í•´ë‹¹ ì—†ëŠ” ê²½ìš° "í•´ë‹¹ ì—†ìŒ" í‘œê¸°
- ë§ì¤„ì„í‘œ(...) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ì¶”ì¸¡ì„± í‘œí˜„ë³´ë‹¤ëŠ” íŒ©íŠ¸ ê¸°ë°˜ ë¶„ì„ ìš°ì„ 

[ë‰´ìŠ¤ ê¸°ì‚¬ ì›ë¬¸]
${article}
`;
    } else {
      return `
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ 3ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸ë¡œ ìš”ì•½í•´ì¤˜:
- ì „ëµì  ê´€ì ì—ì„œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ
- ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ
- ë§ì¤„ì„í‘œ(...) ì‚¬ìš© ê¸ˆì§€
- ì˜ì–´ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ìš”ì•½

[ê¸°ì‚¬ ì›ë¬¸]
${article}
`;
    }
  }

  startQueueProcessor() {
    setInterval(() => {
      if (!this.processing && this.queue.length > 0) {
        this.processQueue();
      }
    }, 1000);
  }

  async processQueue() {
    if (this.queue.length === 0 || this.processing) return;
    
    this.processing = true;
    const batch = this.queue.splice(0, this.concurrency);
    
    try {
      await Promise.all(batch.map(task => this.executeTask(task)));
    } catch (error) {
      logger.error('Queue processing error:', error);
    } finally {
      this.processing = false;
    }
  }

  async executeTask(task) {
    try {
      const result = await task.fn();
      task.resolve(result);
    } catch (error) {
      task.reject(error);
    }
  }

  async queueTask(fn) {
    return new Promise((resolve, reject) => {
      this.queue.push({ fn, resolve, reject });
    });
  }

  /** -------- í–¥ìƒëœ Chat Completions API ìš”ì•½ -------- */
  async summarizeArticleStreaming(article, {
    model = "gpt-4.1-mini",
    timeoutMs = 60_000,
    retries = 4,
    detailed = false
  } = {}) {
    if (!this.client) {
      throw new Error('OpenAI client not initialized');
    }

    const startedAt = Date.now();
    const reqId = `req_${startedAt}_${Math.random().toString(36).slice(2, 8)}`;

    logger.info(`summarize start - reqId: ${reqId}, model: ${model}, timeout: ${timeoutMs}ms`);

    const { signal, cleanup } = this.withTimeout(undefined, timeoutMs);

    try {
      const response = await this.retryWithBackoff(async () => {
        return await this.client.chat.completions.create({
          model,
          messages: [
            { role: "system", content: this.getSystemMessage() },
            { role: "user", content: this.buildUserMessage(article, detailed) }
          ],
          temperature: 0.3,
          max_tokens: detailed ? 2000 : 1000,
        }, { signal });
      }, {
        retries,
        onRetry: ({ attempt, delay, status, err }) => {
          logger.warn(`retrying after error - reqId: ${reqId}, attempt: ${attempt}, delay: ${delay}ms, status: ${status}, error: ${String(err)}`);
        }
      });

      this.updateRateLimits(response.headers || {});

      const finalText = response.choices[0]?.message?.content?.trim();
      
      if (!finalText) {
        throw new Error('Empty response from OpenAI');
      }

      logger.info(`summarize done - reqId: ${reqId}, elapsed: ${Date.now() - startedAt}ms, response_id: ${response?.id}, textLength: ${finalText?.length || 0}`);

      return finalText;
    } finally {
      cleanup?.();
    }
  }

  // ê¸°ì¡´ API í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ ë©”ì„œë“œë“¤
  async summarize(text, options = {}) {
    const isDetailed = options.detailed || false;
    const cacheKey = `summary:${isDetailed ? 'detailed:' : 'simple:'}${Buffer.from(text).toString('base64').substring(0, 32)}`;
    
    try {
      const cached = await this.cache.get(cacheKey);
      if (cached) {
        return { success: true, data: { summary: cached } };
      }

      const summary = await this.queueTask(() => 
        this.summarizeArticleStreaming(text, { detailed: isDetailed })
      );

      // ìºì‹œ ì €ì¥ (1ì‹œê°„)
      await this.cache.set(cacheKey, summary, 3600);

      return {
        success: true,
        data: { summary }
      };
    } catch (error) {
      logger.error('Summarization failed:', error);
      return {
        success: false,
        error: error.message
      };
    }
  }

  async translate(text, targetLang = 'ko') {
    const cacheKey = `translate:${targetLang}:${Buffer.from(text).toString('base64').substring(0, 32)}`;
    
    try {
      const cached = await this.cache.get(cacheKey);
      if (cached) {
        return { success: true, data: { translated: cached } };
      }

      if (!this.client) {
        throw new Error('OpenAI client not initialized');
      }

      const response = await this.retryWithBackoff(async () => {
        return await this.client.chat.completions.create({
          model: 'gpt-4.1-mini',
          messages: [
            {
              role: 'system',
              content: `You are a professional translator. Translate the following text to ${targetLang === 'ko' ? 'Korean' : targetLang}. Maintain the original meaning and tone. Do not add explanations.`
            },
            {
              role: 'user',
              content: text
            }
          ],
          temperature: 0.3,
          max_tokens: 2000
        });
      });

      this.updateRateLimits(response.headers || {});

      const translated = response.choices[0]?.message?.content?.trim();
      
      if (!translated) {
        throw new Error('Empty translation response');
      }

      // ìºì‹œ ì €ì¥ (1ì‹œê°„)
      await this.cache.set(cacheKey, translated, 3600);

      return {
        success: true,
        data: { translated }
      };
    } catch (error) {
      logger.error('Translation failed:', error);
      return {
        success: false,
        error: error.message
      };
    }
  }

  async generateSummaryPoints(text, maxPoints = 5) {
    try {
      const result = await this.summarize(text, { detailed: true });
      if (!result.success) {
        return [];
      }

      // ì‘ë‹µì—ì„œ ë¸”ë¦¿í¬ì¸íŠ¸ ì¶”ì¶œ
      const summary = result.data.summary;
      const lines = summary.split('\n').filter(line => line.trim());
      const points = [];

      for (const line of lines) {
        if (line.includes('â€¢') || line.includes('-') || line.includes('*')) {
          const point = line.replace(/^[â€¢\-*]\s*/, '').trim();
          if (point && points.length < maxPoints) {
            points.push(point);
          }
        }
      }

      return points.length > 0 ? points : [summary.substring(0, 200) + '...'];
    } catch (error) {
      logger.error('Summary points generation failed:', error);
      return ['ìš”ì•½ ì •ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'];
    }
  }

  updateRateLimits(headers) {
    if (headers) {
      this.remainingRequests = parseInt(headers['x-ratelimit-remaining-requests'] || this.remainingRequests);
      this.remainingTokens = parseInt(headers['x-ratelimit-remaining-tokens'] || this.remainingTokens);
    }
  }

  logOpenAIError(error, context) {
    if (error.response) {
      logger.error(`[OpenAI API Error - ${context}] Status: ${error.response.status}, Data: ${JSON.stringify(error.response.data)}`);
      if (error.response.status === 429) {
        logger.warn('OpenAI rate limit exceeded');
      }
    } else if (error.request) {
      logger.error(`[OpenAI API No Response - ${context}] Timeout or Network error: ${error.message}`);
    } else {
      logger.error(`[OpenAI API Request Setup Error - ${context}]: ${error.message}`);
    }
  }

  isKorean(text) {
    if (!text) return false;
    const koreanRegex = /[\uac00-\ud7a3]/g;
    const textLength = text.replace(/\s+/g, '').length;
    if (textLength === 0) return false;
    const koreanMatches = (text.match(koreanRegex) || []).length;
    return (koreanMatches / textLength) > 0.3; // 30% ì´ìƒì´ í•œê¸€ì´ë©´ í•œêµ­ì–´ë¡œ ê°„ì£¼
  }

  getStatus() {
    return {
      initialized: !!this.client,
      queueLength: this.queue.length,
      processing: this.processing,
      concurrency: this.concurrency,
      remainingRequests: this.remainingRequests,
      remainingTokens: this.remainingTokens,
      deadLetterQueueSize: this.deadLetterQueue.length
    };
  }
}

module.exports = AIService;

